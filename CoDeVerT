Graph-Based Controversy Detection for Versioned Text (CoDeVerT)

Intro

When reviewing some versioned body of text - an article edit history, an evolving standards document, or an active code base - one might want to know which parts have been controversial and when. This information could help readers evaluate the relative trustworthiness/reliability of different sections and editors identify where their services are most needed. we might want to find out what aspects of Star Wars lore were most contested on Wikipedia in the aftermath of the new movies; we might be interested in what the ISO C++ committee is currently thinking about changing for C++20; we might need to know what part of the concurrency model in some filesystem implementation currently has engineers butting heads. Of course, to do any of this, we need to know what 'controversy' actually means and have a way of measuring it.

In this paper we propose a metric for identifying controversy and a technique for calculating it across a document edit history (DEH). Under our model, controversy is the total semantic distance traveled by a text segment across a DEH. The intuition here is that a section is controversial if it has been repeatedly changed in ways that actually alter its meaning. To make the problem tractable, we convert a DEH into a series of diffs and then embed those in a directed acyclic graph (DAG). Subsequently, we can measure the controversy of any node as its height in the graph. In order to show that our technique captures something at least highly correlated with our common-sense understanding of controversy, we examine case studies across a variety of domains. Future work may include more formal user-studies.

Constructing the DAG

In order to convert a DEH into a DAG, we convert every document version into a vector of 'words' corresponding to logical subdivisions of the document. For plain-text, these are naturally just actual words, but for code, we use an AST to split the document into syntactically meaningful chunks. We then diff adjacent vectors, giving us a series of patch sets, each corresponding to a document version. A patch set (P_n) contains a collection of uniquely identified INSERTS and DELETES, each representing the addition or removal of contiguous words at some position in the previous version of the document.

Starting with the initial document, which we treat as a single INSERT, for each version we maintain an ordered list of (position, patch ID) tuples where every position corresponds to the start of a patch in the current document version. The range of every patch is implied by the position of the next list entry. Notably a DELETE has range 0, such that it can share a position with other entries, making the ordering of the list very important. At the V_0 therefore, our list has a single entry (0,0). When updating our list with a new patch set, each INSERT is added as (INSERT.pos, INSERT.id) and every patch position in the list greater than INSERT.pos is increased by INSERT.size. If an INSERT interrupts an existing patch, that patch is split up into (PATCH.pos, PATCH.id) and (PATCH.pos+INSERT.size, PATCH.id). Each DELETE is added to the list as (DELETE.pos, DELETE.id). If a patch's position falls within the range of the DELETE (between DELETE.pos and DELETE.pos+DELETE.size), its corresponding entry is removed from the list unless the DELETE doesn't complete cover the patch range, in which case the position is updated to DELETE.pos

